## Aerial Tracking
1. Resource-Efficient RGBD Aerial Tracking (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.pdf)

## Optical Flow
1. Perspective Flow Aggregation for Data-Limited 6D Object Pose Estimation (ECCV 2022) [PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136620087.pdf)
2. FlowFormer: A Transformer Architecture for Optical Flow (ECCV 2022) [PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136770672.pdf)
3. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume (CVPR 2018) [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.pdf)
4. FlowNet: Learning Optical Flow with Convolutional Networks (ICCV 2015) [CVPR](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Dosovitskiy_FlowNet_Learning_Optical_ICCV_2015_paper.pdf)
5. Flownet 2.0: Evolution of optical flow estimation with deep networks (CVPR 2017) [PDF](https://openaccess.thecvf.com/content_cvpr_2017/papers/Ilg_FlowNet_2.0_Evolution_CVPR_2017_paper.pdf)

## Multi-Task Architectures
1. Efficient Controllable Multi-Task Architectures (ICCV 2023) [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf)
2. Multi-Task Learning with Knowledge Distillation for Dense Prediction (ICCV 2023) [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf)
3. Multi-task learning for dense prediction tasks: A survey (TPAMI 2022) [PDF](https://arxiv.org/pdf/2004.13379.pdf)
4. Pattern-Structure Diffusion for Multi-Task Learning (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_Pattern-Structure_Diffusion_for_Multi-Task_Learning_CVPR_2020_paper.pdf)
5. PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing (CPVR 2018) [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf)
6. Leveraging Auxiliary Tasks with Affinity Learning for Weakly Supervised Semantic Segmentation (ICCV 2021) [PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_Leveraging_Auxiliary_Tasks_With_Affinity_Learning_for_Weakly_Supervised_Semantic_ICCV_2021_paper.pdf)
7. MTFormer: Multi-Task Learning via Transformer and Cross-Task Reasoning (ECCV 2022) [PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870299.pdf)
8. Multi-Mode Online Knowledge Distillation for Self-Supervised Visual Representation Learning (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Multi-Mode_Online_Knowledge_Distillation_for_Self-Supervised_Visual_Representation_Learning_CVPR_2023_paper.pdf)
9. End-to-End Multi-Task Learning with Attention (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.pdf)

## Self-Supervised Object Pose Estimation
1. Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation (ICCV 2023) [PDF](https://arxiv.org/pdf/2308.10016.pdf)
2. Self6D: Self-Supervised Monocular 6D Object Pose Estimation (ECCV 2020) [PDF](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460103.pdf)
3. Self6D++: Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation (TPAMI 2022) [PDF](https://arxiv.org/pdf/2203.10339.pdf)
4. TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_TexPose_Neural_Texture_Learning_for_Self-Supervised_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf)
5. UDA-COPE: Unsupervised Domain Adaptation for Category-level Object Pose Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf)
6. SMOC-Net: Leveraging Camera Pose for Self-Supervised Monocular Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_SMOC-Net_Leveraging_Camera_Pose_for_Self-Supervised_Monocular_Object_Pose_Estimation_CVPR_2023_paper.pdf)

## Neural Radiance Fields
1. NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (ICCV 2020) [PDF](https://arxiv.org/pdf/2003.08934v2.pdf)
2. NeRF: Neural Radiance Field in 3D Vision, Introduction and Review [PDF](https://arxiv.org/pdf/2210.00379.pdf)
3. DINER: Depth-aware Image-based NEural Radiance fields (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Prinzler_DINER_Depth-Aware_Image-Based_NEural_Radiance_Fields_CVPR_2023_paper.pdf)

## 6D Object Pose Estimation
1. Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf)
5. DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_DenseFusion_6D_Object_Pose_Estimation_by_Iterative_Dense_Fusion_CVPR_2019_paper.pdf)
6. PVN3D: A Deep Point-wise 3D Keypoints Voting Network for 6DoF Pose Estimation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_PVN3D_A_Deep_Point-Wise_3D_Keypoints_Voting_Network_for_6DoF_CVPR_2020_paper.pdf)
7. FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/He_FFB6D_A_Full_Flow_Bidirectional_Fusion_Network_for_6D_Pose_CVPR_2021_paper.pdf)
8. Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation (TPAMI 2021) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9655492)
10. SMOC-Net: Leveraging Camera Pose for Self-Supervised Monocular Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_SMOC-Net_Leveraging_Camera_Pose_for_Self-Supervised_Monocular_Object_Pose_Estimation_CVPR_2023_paper.pdf)
11. PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes (RSS 2018) [PDF](https://arxiv.org/pdf/1711.00199.pdf)
12. EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.pdf)
13. DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.pdf)
14. Single-stage 6d object pose estimation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Single-Stage_6D_Object_Pose_Estimation_CVPR_2020_paper.pdf)
15. GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.pdf)
16. End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_End-to-End_Learnable_Geometric_Vision_by_Backpropagating_PnP_Optimization_CVPR_2020_paper.pdf)
17. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Peng_PVNet_Pixel-Wise_Voting_Network_for_6DoF_Pose_Estimation_CVPR_2019_paper.pdf)
18. Segmentation-driven 6D Object Pose Estimation (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_Segmentation-Driven_6D_Object_Pose_Estimation_CVPR_2019_paper.pdf)
19. HybridPose: 6D Object Pose Estimation under Hybrid Representation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Song_HybridPose_6D_Object_Pose_Estimation_Under_Hybrid_Representations_CVPR_2020_paper.pdf)
20. SO-Pose: Exploiting Self-Occlusion for Direct 6D Pose Estimation (ICCV 2021) [PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Di_SO-Pose_Exploiting_Self-Occlusion_for_Direct_6D_Pose_Estimation_ICCV_2021_paper.pdf)
21. Keypoint-graph-driven learning framework for object pose estimation (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.pdf)
22. Object Pose Estimation with Statistical Guarantees: Conformal Keypoint Detection and Geometric Uncertainty Propagation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf)
23. Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview [PDF](https://dl.acm.org/doi/full/10.1145/3524496)
24. Data-Driven Grasp Synthesisâ€”A Survey (TRO) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6672028)
25. Rigidity-Aware Detection for 6D Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Hai_Rigidity-Aware_Detection_for_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf)
    
## 6D Object Pose Estimation (without CAD Model)
1. GPV-Pose: Category-Level Object Pose Estimation via Geometry-Guided Point-Wise Voting (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf)
2. OnePose: One-Shot Object Pose Estimation without CAD Models (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf)
3. SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf)
4. OSOP: A Multi-Stage One Shot Object Pose Estimation Framework (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.pdf)
5. Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.pdf)
6. HS-Pose: Hybrid Scope Feature Extraction for Category-level Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_HS-Pose_Hybrid_Scope_Feature_Extraction_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf)
   
## Hand Pose Estimation
1. HARP: Personalized Hand Reconstruction from a Monocular RGB Video (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Karunratanakul_HARP_Personalized_Hand_Reconstruction_From_a_Monocular_RGB_Video_CVPR_2023_paper.pdf)
2. HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.pdf)
3. Harmonious Feature Learning for Interactive Hand-Object Pose Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Harmonious_Feature_Learning_for_Interactive_Hand-Object_Pose_Estimation_CVPR_2023_paper.pdf)
4. Learning Human-to-Robot Handovers from Point Clouds (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Harmonious_Feature_Learning_for_Interactive_Hand-Object_Pose_Estimation_CVPR_2023_paper.pdf)
5. Keypoint Transformer: Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf)
6. Learning joint reconstruction of hands and manipulated objects (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Hasson_Learning_Joint_Reconstruction_of_Hands_and_Manipulated_Objects_CVPR_2019_paper.pdf)
7. Leveraging Photometric Consistency over Time for Sparsely Supervised Hand-Object Reconstruction (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Hasson_Leveraging_Photometric_Consistency_Over_Time_for_Sparsely_Supervised_Hand-Object_Reconstruction_CVPR_2020_paper.pdf)
8. HOPE-Net: A Graph-based Model for Hand-Object Pose Estimation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Doosti_HOPE-Net_A_Graph-Based_Model_for_Hand-Object_Pose_Estimation_CVPR_2020_paper.pdf)
9. Reconstructing Hand-Object Interactions in the Wild (ICCV 2021) [PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Cao_Reconstructing_Hand-Object_Interactions_in_the_Wild_ICCV_2021_paper.pdf)
10. DexYCB: A Benchmark for Capturing Hand Grasping of Objects (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Chao_DexYCB_A_Benchmark_for_Capturing_Hand_Grasping_of_Objects_CVPR_2021_paper.pdf)
11. ARCTIC: A Dataset for Dexterous Bimanual Hand-Object Manipulation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_ARCTIC_A_Dataset_for_Dexterous_Bimanual_Hand-Object_Manipulation_CVPR_2023_paper.pdf)
12. AMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_CAMS_CAnonicalized_Manipulation_Spaces_for_Category-Level_Functional_Hand-Object_Manipulation_Synthesis_CVPR_2023_paper.pdf)
13. Affordance Diffusion: Synthesizing Hand-Object Interactions (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Affordance_Diffusion_Synthesizing_Hand-Object_Interactions_CVPR_2023_paper.pdf)
14. gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_gSDF_Geometry-Driven_Signed_Distance_Functions_for_3D_Hand-Object_Reconstruction_CVPR_2023_paper.pdf)
15. End-to-End Human Pose and Mesh Reconstruction with Transformers (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.pdf)
    
## Multi-Modal Fusion
1. RGB-Depth Fusion GAN for Indoor Depth Completion (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.pdf)
2. MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth Seeds for 3D Object Detection (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiao_MSMDFusion_Fusing_LiDAR_and_Camera_at_Multiple_Scales_With_Multi-Depth_CVPR_2023_paper.pdf)
3. PGDENet: Progressive Guided Fusion and Depth Enhancement Network for RGB-D Indoor Scene Parsing [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9740493)
4. RGB-Depth Fusion GAN for Indoor Depth Completion [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.pdf)
5. FRNet: Feature Reconstruction Network for RGB-D Indoor Scene Parsing [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9774020)
6. CANet: Co-attention network for RGB-D semantic segmentation [PDF](https://www.sciencedirect.com/science/article/pii/S0031320321006440/pdf)
7. Exploiting enhanced and robust RGB-D face representation via progressive multi-modal learning (PRL 2023) [PDF](https://www.sciencedirect.com/science/article/pii/S0167865522003956?ref=pdf_download&fr=RR-2&rr=7e2c34afedd209a8)
8. CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation With Transformers [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10231003)
9. PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration (ICCV 2023) [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf)
   
## Attention
1. Attention Mechanisms in Computer Vision: A Survey [PDF](https://arxiv.org/pdf/2111.07624.pdf)
2. Attention is All You Need [PDF](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
3. Non-local Neural Networks (CVPR 2018) [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf)
4. Squeeze-and-Excitation Networks (CVPR 2018) [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf)
5. CBAM: Convolutional Block Attention Module (ECCV 2018) [PDF](https://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf)
6. CCNet: Criss-Cross Attention for Semantic Segmentation (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_CCNet_Criss-Cross_Attention_for_Semantic_Segmentation_ICCV_2019_paper.pdf)
7. Compact Generalized Non-local Network [PDF](https://arxiv.org/pdf/1810.13125.pdf)
8. ACFNet: Attentional Class Feature Network for Semantic Segmentation [ICCV 2019](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_ACFNet_Attentional_Class_Feature_Network_for_Semantic_Segmentation_ICCV_2019_paper.pdf)
9. Dual Attention Network for Scene Segmentation (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.pdf)
10. PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval (CVPR 2019) [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_PCAN_3D_Attention_Map_Learning_Using_Contextual_Information_for_Point_CVPR_2019_paper.pdf)
11. Geodesic Self-Attention for 3D Point Clouds (NIPS 2022) [PDF](https://proceedings.neurips.cc/paper_files/paper/2022/file/28e4ee96c94e31b2d040b4521d2b299e-Paper-Conference.pdf)
12. Cross-task Attention Mechanism for Dense Multi-task Learning (WACV 2023) [PDF](https://openaccess.thecvf.com/content/WACV2023/papers/Lopes_Cross-Task_Attention_Mechanism_for_Dense_Multi-Task_Learning_WACV_2023_paper.pdf)
13. Investigating Attention Mechanism in 3D Point Cloud Object Detection (3DV 2021) [PDF](https://arxiv.org/pdf/2108.00620.pdf) 

## Transformer
1. Visual Guide to Transformer Neural Networks - (Episode 1) Position Embeddings [Youtube](https://www.youtube.com/watch?v=dichIcUZfOw)
2. Transformer Architecture: The Positional Encoding [Blog](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
3. Transformers in Vision: A Survey [PDF](https://arxiv.org/pdf/2101.01169.pdf)
4. Published as a conference paper at ICLR 2021 AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE (ICLR 2021) [PDF](https://arxiv.org/pdf/2010.11929.pdf)
5. End-to-End Human Object Interaction Detection with HOI Transformer [PDF]()
6. Attention Augmented Convolutional Networks [PDF](https://arxiv.org/pdf/1904.09925.pdf)

## Depth Estimation
1. SDC-Depth: Semantic Divide-and-Conquer Network for Monocular Depth Estimation (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SDC-Depth_Semantic_Divide-and-Conquer_Network_for_Monocular_Depth_Estimation_CVPR_2020_paper.pdf)
2. Towards Real-Time Monocular Depth Estimation for Robotics: A Survey (STAMP 2022) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9750985)
3. Deep learning for monocular depth estimation: A review (2021) [PDF](https://pure.port.ac.uk/ws/files/26286067/Deep_Learning_for_Monocular_Depth_Estimation_A_Review_pp.pdf)
4. iDisc: Internal Discretization for Monocular Depth Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Piccinelli_iDisc_Internal_Discretization_for_Monocular_Depth_Estimation_CVPR_2023_paper.pdf)
5. Categorical Depth Distribution Network for Monocular 3D Object Detection (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Reading_Categorical_Depth_Distribution_Network_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf)
6. Center3D: Center-based Monocular 3D Object Detection with Joint Depth Understanding [PDF](https://arxiv.org/pdf/2005.13423.pdf)
7. Deep Ordinal Regression Network for Monocular Depth Estimation (CVPR 2018) [PDF](https://openaccess.thecvf.com/content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf)
8. Deeper Depth Prediction with Fully Convolutional Residual Networks (3DV 2016) [PDF](https://arxiv.org/pdf/1606.00373.pdf)
9. P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior (CVPR 2022) [CODE](https://github.com/SysCV/P3Depth) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.pdf)
10. Fine-grained Semantics-aware Representation Enhancement for Self-supervised Monocular Depth Estimation (ICCV 2021) [PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Jung_Fine-Grained_Semantics-Aware_Representation_Enhancement_for_Self-Supervised_Monocular_Depth_Estimation_ICCV_2021_paper.pdf)
11. Learning depth via leveraging semantics: Self-supervised monocular depth estimation with both implicit and explicit semantic guidance (Pattern Recognition) [PDF](https://www.sciencedirect.com/science/article/pii/S0031320322007762?ref=cra_js_challenge&fr=RR-1)

## Depth-Aware Methods
1. Towards Zero-Shot Scale-Aware Monocular Depth Estimation (ICCV 2023) [PDF](https://arxiv.org/pdf/2306.17253.pdf)
2. MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer (CVPR 2022) [CODE](https://github.com/KuanchihHuang/MonoDTR) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.pdf)
3. Learning Depth-Guided Convolutions for Monocular 3D Object Detection (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Ding_Learning_Depth-Guided_Convolutions_for_Monocular_3D_Object_Detection_CVPR_2020_paper.pdf)
4. Dynamic Depth Fusion and Transformation for Monocular 3D Object Detection (ACCV 2020) [PDF](https://openaccess.thecvf.com/content/ACCV2020/papers/Ouyang_Dynamic_Depth_Fusion_and_Transformation_for_Monocular_3D_Object_Detection_ACCV_2020_paper.pdf)
5. Depth-conditioned dynamic message propagation for monocular 3d object detection (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Depth-Conditioned_Dynamic_Message_Propagation_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf)
6. Depth-Aware Generative Adversarial Network for Talking Head Video Generation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.pdf)
7. Depth-Guided Sparse Structure-from-Motion for Movies and TV Shows (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.pdf)
8. PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation (CVPR 2022) [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.pdf)
9. Object aware monocular depth prediction with instance convolutions (ICRA 2022) [PDF](https://arxiv.org/pdf/2112.01521.pdf)
10. Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation (CVPR 2023) [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Lite-Mono_A_Lightweight_CNN_and_Transformer_Architecture_for_Self-Supervised_Monocular_CVPR_2023_paper.pdf)
11. DADA: Depth-Aware Domain Adaptation in Semantic Segmentation (ICCV 2019) [PDF](https://openaccess.thecvf.com/content_ICCV_2019/papers/Vu_DADA_Depth-Aware_Domain_Adaptation_in_Semantic_Segmentation_ICCV_2019_paper.pdf)
12. Does depth estimation help object detection? (ICV 2022) [PDF](https://arxiv.org/pdf/2204.06512.pdf)
    
##  Graph Neural Network
1. Learning Convolutional Neural Networks for Graphs (ICML 2016) [PDF](https://proceedings.mlr.press/v48/niepert16.pdf)
2. Neural Message Passing for Quantum Chemistry (ICML 2016) [PDF](http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf)
3. A Comprehensive Survey on Graph Neural Networks (2019) [PDF](https://arxiv.org/pdf/1901.00596.pdf)
4. Dynamic Graph CNN for Learning on Point Clouds (Transactions On Graphics) [PDF](https://arxiv.org/pdf/1801.07829.pdf)
5. SuperGlue: Learning Feature Matching with Graph Neural Networks (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Sarlin_SuperGlue_Learning_Feature_Matching_With_Graph_Neural_Networks_CVPR_2020_paper.pdf)
6. Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wald_Learning_3D_Semantic_Scene_Graphs_From_3D_Indoor_Reconstructions_CVPR_2020_paper.pdf)

## Segmentation
1.Fully Convolutional Networks for Semantic Segmentation (TPAMI 2017) [PDF](https://openreview.net/pdf?id=SNHz8GbW2Ry)
2. Learning Deconvolution Network for Semantic Segmentation (ICCV 2015) [PDF](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf)
3. Fully convolutional networks for panoptic segmentation (CVPR 2021) [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.pdf)
4. A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D Images [PDF](https://www.tandfonline.com/doi/epdf/10.1080/08839514.2022.2032924?needAccess=true)
5. U-Net: Convolutional Networks for Biomedical Image Segmentation (CVPR 2015) [PDF](https://arxiv.org/pdf/1505.04597.pdf)

## Grasp Detection
1. [GraspNet](https://graspnet.net/publications.html)
2. GraspNet-1Billion: A Large-Scale Benchmark for General Object Grasping (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Fang_GraspNet-1Billion_A_Large-Scale_Benchmark_for_General_Object_Grasping_CVPR_2020_paper.pdf)
3. RGB Matters: Learning 7-DoF Grasp Poses on Monocular RGBD Images (ICRA 2021) [PDF](https://arxiv.org/pdf/2103.02184.pdf)
4. Graspness Discovery in Clutters for Fast and Accurate Grasp Detection (ICCV 2021) [PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Graspness_Discovery_in_Clutters_for_Fast_and_Accurate_Grasp_Detection_ICCV_2021_paper.pdf)
5. TransCG: A Large-Scale Real-World Dataset for Transparent Object Depth Completion and A Grasping Baseline (RAL 2022) [PDF](https://arxiv.org/pdf/2202.08471.pdf)
6. AnyGrasp: Robust and Efficient Grasp Perception in Spatial and Temporal Domains (TRO 2022) [PDF](https://arxiv.org/pdf/2212.08333.pdf)
7. Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes (ICRA 2021) [PDF](https://arxiv.org/pdf/2103.14127.pdf)
8. Joint Segmentation and Grasp Pose Detection with Multi-Modal Feature Fusion Network (ICRA 2023) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160253)
9. Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes (RAL 2023) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10168242)
10. GPDAN: Grasp Pose Domain Adaptation Network for Sim-to-Real 6-DoF Object Grasping (RAL 2023) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10153686)
11. VGPN: 6-DoF Grasp Pose Detection Network Based on Hough Voting (IROS 2022) [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9981925)
12. Robotic Grasping from Classical to Modern: A Survey [PDF](https://arxiv.org/pdf/2202.03631.pdf)
13. RGB-D Grasp Detection via Depth Guided Learning with Cross-modal Attention (ICRA 2023) [PDF](https://arxiv.org/pdf/2302.14264.pdf)
14. MonoGraspNet: 6-DoF Grasping with a Single RGB Image (ICRA 2023) [PDF](https://arxiv.org/pdf/2209.13036.pdf)

## Backbone
1. Deep Hough Voting for 3D Object Detection in Point Clouds (ICCV 2019) [PDF](https://openaccess.thecvf.com/content_ICCV_2019/papers/Qi_Deep_Hough_Voting_for_3D_Object_Detection_in_Point_Clouds_ICCV_2019_paper.pdf)

## Simulator
1. [BlenderProc](https://github.com/DLR-RM/BlenderProc)
2. [Stable Diffusion](https://stablediffusionweb.com/)
   
## Others
1. Incredible summary of the Transformer architecture and it's evolution [Slides](https://docs.google.com/presentation/d/1ZXFIhYczos679r70Yu8vV9uO6B1J0ztzeDxbnBxD1S0/mobilepresent#slide=id.g31364026ad_3_2)
2. Computer Vision Courses at Linkoping [Web](https://isy.gitlab-pages.liu.se/courses/en/?fbclid=IwAR24QlWVRriNVOQR8l863t88avBbO6sotQSPIW5dYXw2ZgzpWQoFajwV0Iw#computer-vision-laboratory)
3. Rethinking Classification and Localization for Object Detection (CVPR 2020) [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Rethinking_Classification_and_Localization_for_Object_Detection_CVPR_2020_paper.pdf)
